# ğŸš€ Enterprise RAG - Advanced Document Analysis System

A comprehensive Retrieval-Augmented Generation (RAG) application with advanced features including citations, confidence scoring, document summarization, and multi-document support.

## âœ¨ Key Features

### Core Features
- ğŸ“„ **PDF Document Processing** - Upload and process PDF documents
- ğŸ’¬ **Intelligent Q&A** - Ask questions about uploaded documents
- ğŸ“š **Citation & Source Tracking** - See exact document locations for answers
- ğŸ“Š **Confidence Scoring** - Know how confident the system is in each answer
- ğŸ“ **Document Summarization** - Auto-generate comprehensive summaries
- ğŸ•¸ï¸ **Knowledge Graph Visualization** - Interactive graph of document relationships
- ğŸ™ï¸ **Audio Podcast Generation** - Convert documents to audio summaries
- ğŸ¤ **Voice Input** - Speak your questions using Web Speech API
- ğŸ“¦ **Multi-Document Support** - Query across multiple documents

### Advanced Features
- âœ… **Proper Error Handling** - Comprehensive error handling and validation
- ğŸ“‹ **API Documentation** - Auto-generated OpenAPI/Swagger docs
- âš™ï¸ **Configuration Management** - Environment-based configuration
- ğŸ“ **Structured Logging** - Professional logging system
- ğŸ”’ **File Validation** - Type and size validation for uploads
- ğŸ¯ **Source Highlighting** - See relevant passages from documents

## ğŸ—ï¸ Architecture

- **Backend**: FastAPI (Python) with LangChain and ChromaDB
- **Frontend**: React.js with modern dark-themed UI
- **LLM**: Ollama (Llama 3) - running locally for privacy
- **Vector Database**: ChromaDB for document embeddings
- **Text-to-Speech**: Google TTS (gTTS)

## ğŸ“‹ Prerequisites

- Python 3.8+
- Node.js 16+
- Ollama installed and running (with llama3 model pulled)
- Internet connection (for Google TTS)

## ğŸš€ Quick Start

### 1. Install Ollama

```bash
# Install Ollama from https://ollama.ai
# Pull the llama3 model
ollama pull llama3
```

### 2. Backend Setup

```bash
# Install Python dependencies
pip install -r requirements.txt

# Create .env file (optional - uses defaults if not present)
cp .env.example .env
# Edit .env with your preferences

# Run the backend server
python run_server.py
# or
uvicorn main:app --reload
```

Backend will run on `http://localhost:8000`

### 3. Frontend Setup

```bash
cd client
npm install
npm start
```

Frontend will run on `http://localhost:3000`

### 4. Access API Documentation

Visit `http://localhost:8000/docs` for interactive API documentation (Swagger UI)

## ğŸ“– Usage

1. **Upload Document**: Click "Upload & Index" to process a PDF
2. **Ask Questions**: Type or speak questions about the document
3. **View Citations**: See source locations and relevant passages
4. **Check Confidence**: View confidence scores for each answer
5. **Generate Summary**: Click "Generate Summary" for document overview
6. **View Knowledge Graph**: Visualize document relationships
7. **Listen to Podcast**: Generate audio summary of document

## ğŸ”§ Configuration

Create a `.env` file in the root directory:

```env
# Server Configuration
HOST=127.0.0.1
PORT=8000
DEBUG=False

# LLM Configuration
LLM_MODEL=llama3
LLM_TEMPERATURE=0
EMBEDDING_MODEL=llama3

# RAG Configuration
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
RETRIEVAL_K=5

# File Upload
MAX_FILE_SIZE_MB=50
ALLOWED_EXTENSIONS=pdf
```

## ğŸ“¡ API Endpoints

### Document Management
- `POST /upload-doc` - Upload and process PDF document
- `GET /documents` - List all uploaded documents
- `GET /documents/{name}` - Get document information

### Query & Analysis
- `GET /ask?query={question}` - Ask a question (with citations & confidence)
- `POST /ask` - Ask a question (JSON body)
- `GET /summarize` - Generate document summary
- `GET /generate-graph` - Generate knowledge graph
- `GET /generate-podcast` - Generate audio podcast

### Health & Info
- `GET /` - API information
- `GET /health` - Health check
- `GET /docs` - Interactive API documentation

## ğŸ¯ Response Format

### Ask Question Response
```json
{
  "answer": "The answer text...",
  "confidence": 0.85,
  "citations": [
    {
      "id": 1,
      "text": "Relevant passage...",
      "page": 5,
      "source": "document.pdf",
      "relevance_score": 0.92
    }
  ],
  "sources": ["document.pdf"],
  "source_count": 3,
  "audio": "base64_encoded_mp3..." // if voice_mode=true
}
```

### Summary Response
```json
{
  "status": "success",
  "summary": "Comprehensive summary text...",
  "document_name": "document.pdf",
  "chunk_count": 45,
  "page_count": 12,
  "generated_at": 1234567890
}
```

## ğŸ› ï¸ Development

### Project Structure
```
Enterprise_RAG/
â”œâ”€â”€ main.py              # FastAPI backend server
â”œâ”€â”€ rag_engine.py        # Core RAG logic
â”œâ”€â”€ config.py            # Configuration management
â”œâ”€â”€ logger_config.py     # Logging setup
â”œâ”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ client/              # React frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.js       # Main React component
â”‚   â”‚   â”œâ”€â”€ GraphModal.js
â”‚   â”‚   â”œâ”€â”€ PodcastModal.js
â”‚   â”‚   â””â”€â”€ SummaryModal.js
â”‚   â””â”€â”€ package.json
â””â”€â”€ db_storage_*/        # ChromaDB storage
```

### Key Improvements Made

1. âœ… Fixed duplicate endpoints
2. âœ… Added missing dependencies (gTTS)
3. âœ… Implemented citation tracking
4. âœ… Added confidence scoring
5. âœ… Created document summarization
6. âœ… Multi-document support
7. âœ… Configuration management (.env)
8. âœ… Proper logging system
9. âœ… File validation
10. âœ… Enhanced error handling
11. âœ… API documentation
12. âœ… Frontend enhancements

## ğŸ› Troubleshooting

### Ollama Connection Issues
```bash
# Make sure Ollama is running
ollama serve

# Verify model is available
ollama list
```

### Port Already in Use
```bash
# Change port in .env file
PORT=8001
```

### Frontend Can't Connect to Backend
- Check CORS_ORIGINS in .env
- Verify backend is running on correct port
- Check browser console for errors

## ğŸ“Š Performance Tips

- Use smaller chunk sizes for faster processing
- Reduce RETRIEVAL_K for faster queries
- Enable file logging only in development
- Use SSD storage for better ChromaDB performance

## ğŸ”’ Security Notes

- Currently configured for local development
- Add authentication for production use
- Configure CORS properly for production
- Validate all user inputs
- Implement rate limiting

## ğŸš€ Future Enhancements

See `FEATURE_ENHANCEMENTS.md` for a comprehensive list of potential features including:
- Multi-modal document analysis
- Advanced semantic search
- User authentication
- Document versioning
- Integration with external systems

## ğŸ“ License

This project is open source and available for educational and portfolio purposes.

## ğŸ‘¨â€ğŸ’» Author

Enterprise RAG System - Advanced Document Analysis Platform

## ğŸ™ Acknowledgments

- LangChain for RAG framework
- ChromaDB for vector storage
- Ollama for local LLM
- FastAPI for backend framework
- React for frontend framework

---

**Built with â¤ï¸ for Enterprise Document Analysis**


